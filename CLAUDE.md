# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is a data analysis project for a Master's thesis in Artificial Intelligence at Radboud University, investigating the impact of communicating technical uncertainties on trust in medical AI systems. The research explores whether transparent communication about AI uncertainties affects patients' trust in Medical Decision Support Systems (MDSS).

## Environment Setup

This project uses **uv** for dependency management with Python 3.14+. The development environment is managed through **DataSpell**, which handles the Jupyter server and virtual environment automatically.

### Installing Dependencies
```bash
# Install/sync dependencies (creates .venv automatically)
uv sync
```

The `uv.lock` file ensures reproducible environments across machines.

## Project Structure

The project consists mainly of python scripts and jupyter notebooks, with data and plots saved separately. All notes and test scripts generated by CLAUDE should go into the `/claude_notes` directory.

### Directory Structure
- `processing/`: Data preprocessing notebooks and scale definitions
- `analysis/`: Analysis notebooks (manipulation checks, univariate/multivariate tests, etc.)
- `scripts/`: Reusable Python modules for statistics, utilities, and visualization
- `plots/`: Generated visualizations, organized by analysis type
  - `manip_check/`: Manipulation check plots
  - `univariate_analysis/`: Univariate regression and equivalence test plots
  - `multivariate_analysis/`: MANOVA and multivariate equivalence plots
  - `overview/`: Demographic and overview plots
- `data/`: Raw and processed data files
- `output/`: Statistical results tables (CSV format)
- `reports/`: Statistical analysis reports (Markdown format)
- `claude_notes/`: Claude-generated notes and test scripts

### Notebooks
- `processing/preprocessing.ipynb`: Data cleaning and preprocessing
- `processing/scales.py`: Scale definitions and variable naming
- `analysis/manip_check.ipynb`: Manipulation check analysis
- `analysis/univariate.ipynb`: Univariate regression analysis with non-inferiority/equivalence tests
- `analysis/multivariate.ipynb`: MANOVA with multivariate equivalence tests
- `analysis/overview_results.ipynb`: Main results visualization and overview

### Python Modules (scripts/)
- `stats.py`: Comprehensive statistical analysis functions (see Statistical Functions section)
- `utils.py`: Data processing utilities (label/question lookups, APA formatting)
- `viz_utils.py`: Visualization utilities and custom plotting functions

### Data Files
- `data/raw_data_qualtrics.csv`: Raw survey data exported from Qualtrics
- `data/data_clean.csv`: Cleaned data after preprocessing
- `data/data_scales.csv`: Data with computed scale scores
- `data/questions.csv`: Survey question metadata
- `data/labels.csv`: Variable labels and descriptions

## Experimental Design

### Stimulus Groups
- `uncertainty`: Treatment condition (AI uncertainty communicated)
- `control`: No uncertainty communication

### Measured Constructs

**Primary Outcome Variables:**
- **Trust in Automation scale (adapted)** (Körber, 2019)
  - Five subscales measuring different dimensions of trust in AI systems:
    - `tia_rc`: Reliability/Competence - Capability-based trust in system performance
    - `tia_up`: Understanding/Predictability - Shared mental model with the system
    - `tia_f`: Familiarity - Prior experience and comfort with similar systems
    - `tia_pro`: Propensity to Trust - General disposition to trust automation
    - `tia_t`: Trust in Automation - Overall trust in the AI system

**Moderator/Covariate Variables:**
- **Affinity for Technology Interaction (ATI)** (Franke et al., 2019)
  - Single scale (`ati`) measuring general technology affinity and engagement

- **Revised Health Care System Distrust Scale (HCSDS)** (Shea et al., 2008)
  - Note: Interpretation inverted to measure *trust* instead of distrust
  - Two subscales:
    - `hcsds_c`: Competence - Trust in healthcare system's technical capabilities
    - `hcsds_v`: Values - Trust in healthcare system's benevolence and alignment

**Demographics:**
- `age`: Continuous variable (years)
- `gender`: Categorical (1=male, 2=female, 3=other/prefer not to say)
- `education`: Ordinal scale of educational attainment
- `ai_exp`: Self-reported AI experience level (labeled as `Q19` in raw data)
- `medical_prof`: Binary indicator for medical professional status

**Manipulation Checks:**
- Four items (`manip_check1_1` through `manip_check1_4`) assessing:
  - Whether participants noticed uncertainty information
  - Understanding of uncertainty communication
  - Attention to stimulus content

## Data Processing Notes

### Preprocessing workflow:
1. Remove Qualtrics metadata rows (indices 0, 1)
2. Drop unnecessary timing and metadata columns
3. Combine split `delay_timer_Page Submit` columns into single `page_submit` variable
4. Remove incomplete samples
5. Compute scale scores for ATI, healthcare trust, and Trust in Automation
6. Output cleaned data to `data/data_clean.csv` and scale scores to `data/data_scales.csv`

### Key Variables
- `stimulus_group`: Experimental condition (0=control, 1=uncertainty)
- `group_effect`: Effect-coded treatment variable (-0.5=control, 0.5=uncertainty)
- `page_submit`: Time spent viewing stimulus (seconds)
- `gender`, `age`, `education`, `medical_prof`: Demographics
- Scale item prefixes: `ATI_*`, `TiA_*` (Trust in Automation items)
- Centered variables: Suffix `_c` indicates mean-centered or standardized variable (e.g., `ati_c`, `age_c`)

### Output Files

**Statistical Results (output/):**
- `manova_results.csv`: MANOVA results with Pillai's Trace statistics, effect sizes, and adjusted p-values
- `*_regression_coef.csv`: Regression coefficients for each TiA subscale (where * = tia_f, tia_pro, tia_rc, tia_up, tia_t)
  - Includes: coefficients, standard errors, t-values, p-values, confidence intervals, adjusted p-values, partial eta-squared
- `regression_model_stats.csv`: Model fit statistics (R², adjusted R², F-statistic) for all regression models
- `multivariate_eq_test_res.json`: Multivariate equivalence test results (effect size, CI, equivalence margin)

**Reports (reports/):**
- Markdown-formatted statistical reports with comprehensive analysis summaries

## Statistical Analysis Procedures

This project employs a comprehensive statistical analysis framework to investigate the effect of uncertainty communication on trust in medical AI systems.

### Analysis Workflow

1. **Data Preparation**
   - Effect coding: `stimulus_group` coded as -0.5 (control) and 0.5 (uncertainty)
   - Standardization: All continuous variables centered and scaled (z-scores)
   - Effect coding for categorical variables (gender: male=0.5, female=-0.5, other=0)
   - Mean-centering for ordinal variables (education, AI experience)

2. **Univariate Analysis** (analysis/univariate.ipynb)
   - Multiple linear regression for each TiA subscale separately
   - Predictors:
     - Main effect: `group_effect` (treatment condition)
     - Direct effects: Demographics (age, gender, education, AI experience), healthcare trust (competence, values), technology affinity
     - Interaction effects: `group_effect × each predictor` (moderation analysis)
   - Effect size: Partial eta-squared (η²ₚ) computed from t-statistics
   - Multiple comparison correction: Holm method applied per family
     - Family 1: Group effect (main treatment effect)
     - Family 2: Direct effects (all covariates/moderators)
     - Family 3: Interaction effects (all moderation terms)

3. **Multivariate Analysis** (analysis/multivariate.ipynb)
   - MANOVA with all five TiA subscales as dependent variables
   - Same predictor structure as univariate analysis
   - Test statistic: Pillai's Trace (robust to assumption violations)
   - Effect size: Partial eta-squared for multivariate effect
   - Multiple comparison correction: Holm method per family (same structure as univariate)

4. **Equivalence Testing**
   - **Non-inferiority tests**: Determine minimally detectable effect (MDE) based on study design
     - Univariate MDE: Computed from regression standard errors using `(t_α/2 + t_β) × SE`
     - Tests whether observed effect is smaller than MDE (supports "no meaningful harm")
   - **Equivalence tests**: Tests whether effect is statistically equivalent to zero
     - Uses partial eta-squared (η²ₚ) as standardized effect size
     - Equivalence margin: MDE converted to η²ₚ scale
     - Confidence intervals: Computed via non-central F distribution inversion (Steiger, 2004)
     - Tests both univariate effects and multivariate effect
   - Combined visualization showing multivariate + all univariate tests

### Statistical Functions (scripts/stats.py)

The `stats.py` module provides the following categories of functions:

**Parametric Tests:**
- `independent_t_test()`: Welch's t-test (unequal variances)
- `one_way_anova()`: One-way ANOVA for 3+ groups
- `cohens_d()`: Effect size for t-tests
- `eta_squared()`: Effect size for ANOVA

**Non-parametric Tests:**
- `mann_whitney_u_test()`: Non-parametric alternative to t-test
- `rank_biserial_correlation()`: Effect size for Mann-Whitney U
- `kruskal_wallis_test()`: Non-parametric alternative to ANOVA

**Categorical Tests:**
- `chi_square_test()`: Chi-square test of independence
- `fisher_exact_test()`: Exact test for 2×2 tables
- `cramers_v()`: Effect size for chi-square

**Correlation:**
- `pearson_correlation()`: Parametric correlation (linear relationships)
- `spearman_correlation()`: Non-parametric correlation (monotonic relationships)

**Moderation Analysis:**
- `moderation_analysis()`: Regression with interaction terms
- `test_moderation()`: Legacy moderation function
- `print_moderation_results()`: Formatted output
- `interpret_moderation()`: Generate interpretation text
- `interpret_direct_effect()`: Generate interpretation for main effects
- `format_effect_with_stars()`: APA-style significance markers

**Effect Size Confidence Intervals:**
- `eta_confidence_interval()`: CI for partial eta-squared using non-central F distribution inversion
  - Supports both univariate (regression t → F) and multivariate (MANOVA) contexts
  - Method: Steiger (2004) non-central F inversion
  - Parameters: `F_obs`, `df1`, `df2`, `df_error`, `alpha`

**Utility Functions (scripts/utils.py):**
- `get_label_for_value()`: Convert numeric values to survey response labels
- `get_value_for_label()`: Convert labels to numeric values
- `get_question_statement()`: Retrieve question text for items
- `apa_p()`: Format p-values in APA style (with optional significance stars)

**Visualization Functions (scripts/viz_utils.py):**
- Distribution plots for Likert scales, categorical, and continuous variables
- `plot_noninferiority_test()`: Specialized visualization for equivalence/non-inferiority tests
  - Supports both non-inferiority and equivalence modes
  - Shows point estimates with confidence intervals
  - Displays equivalence margins (SESOI - Smallest Effect Size of Interest)
  - Categorical grouping support
- Boxplots, mirrored histograms, split histograms
- Scatterplots with correlation statistics
- All functions support grouping by experimental condition

### Multiple Comparison Correction

To control family-wise error rate, the Holm-Bonferroni method is applied separately to three families of tests:

1. **Group Effect Family**: Main treatment effect (1 test)
2. **Direct Effects Family**: Main effects of all covariates/moderators (8 tests: age, gender, education, AI experience, 2 healthcare trust subscales, ATI)
3. **Interaction Effects Family**: All moderation effects (8 tests: group × each covariate)

This family-wise approach balances Type I error control with statistical power by grouping conceptually related tests.

**Rationale**:
- Main treatment effect tested separately (primary hypothesis)
- Direct effects test whether covariates predict outcomes (exploratory)
- Interactions test whether treatment effect varies by covariates (exploratory moderation)

### Power Analysis Parameters

Standard parameters used across analyses:
- Significance level: α = 0.05 (two-tailed)
- Desired power: 1-β = 0.80
- Sample size: N = 255 (Control: n=126, Uncertainty: n=129)
- Number of outcomes (MANOVA): p = 5 (five TiA subscales)
- Number of groups: k = 2

## Dependencies
- pandas: Data manipulation
- numpy: Numerical operations
- matplotlib: Visualization
- scipy: Statistical analysis (stats, optimize)
- statsmodels: Regression, MANOVA, multitest corrections
- seaborn: Enhanced visualizations
- notebook: Jupyter environment
- pandas-stubs: Type hints for pandas
